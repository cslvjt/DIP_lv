{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import io\n",
    "from skimage.metrics import peak_signal_noise_ratio,structural_similarity\n",
    "def main(ratio):\n",
    "    ###############################################################################\n",
    "    # 读取图片，并转换为 y,v, u 分量。\n",
    "    img = cv2.imread(r'../assest/lean.jpg')\n",
    "    h, w = img.shape[:2]  # 高，宽\n",
    "\n",
    "    # 将 BGR 转换为 YCrCb（YCrCb 应用 YCrCb JPEG（或 YCC），“全范围”，\n",
    "    # 其中 Y 范围为 [0, 255]，U、V 范围为 [0, 255]（这是默认的 JPEG 格式颜色空间格式）。\n",
    "\n",
    "    yvu = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    y, v, u = cv2.split(yvu)\n",
    "\n",
    "    # 下采样 U 和 V（应用 420 格式）。\n",
    "    u = cv2.resize(u, (u.shape[1] // 2, u.shape[0] // 2))  # 要注意 w或h 为单数的情况\n",
    "    v = cv2.resize(v, (v.shape[1] // 2, v.shape[0] // 2))\n",
    "\n",
    "    ############################################################################\n",
    "    # 打开内存中的字节流（而不是使用 文件）\n",
    "    # 将 Y、U 和 V 写入“流”。之后就可以以字节的形式读取，\n",
    "    # 这个是为了模拟读取YUV文件的情况，直接由上面的yuv分量转换形状为一维数据应该也可以\n",
    "    # 这样做的原因是我在网上找的DPCM的C语言版本都是直接读取 .yuv文件的，我为了遵循他们，就这么处理了（其实是懒。。）\n",
    "\n",
    "    f = io.BytesIO()\n",
    "\n",
    "    # Write Y, U and V to the \"streams\".\n",
    "    f.write(y.tobytes())\n",
    "    f.write(u.tobytes())\n",
    "    f.write(v.tobytes())\n",
    "    f.seek(0)\n",
    "\n",
    "    img_np = np.frombuffer(f.read(), np.uint8)  # 原图的yuv420,一定要420,要不然要修改数组截取大小\n",
    "\n",
    "    img_yuv_len = img_np.size\n",
    "    img_y_len = h * w\n",
    "\n",
    "    y = img_np[:img_y_len]\n",
    "    u = img_np[img_y_len:(img_yuv_len - img_y_len) // 2 + img_y_len]  # 要注意 w或h 为单数的情况\n",
    "    v = img_np[(img_yuv_len - img_y_len) // 2 + img_y_len:]\n",
    "    # print(img_np.size)  # 16328\n",
    "    ############################################################################\n",
    "    # DPCM量化编码，采用边编码，边解码的形式，核心是下面for循环部分\n",
    "    img_re = np.zeros(img_y_len, np.uint16)  # 用来存储重建图像,因为中间计算可能超过255，先用16，后面转回8\n",
    "    yprebuff = np.zeros(img_y_len, np.uint16)  # 预测\n",
    "    # print(prebuff.size) # 8164\n",
    "    # print(prebuff.shape) # (8164,)\n",
    "\n",
    "    radio=512/(1<<ratio)  # //量化因子  8是左向预测8bit量化，如果要进行4或2等的自行更改\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            # 左向预测8bit量化\n",
    "            if j == 0:\n",
    "                # 每行第一个像素要进行特殊处理，或保留，或进行一定预测，本设计中是做一定变换预测\n",
    "                ypre = y[j + i * w]-128  # 计算预测误差\n",
    "                yprebuff[j + i * w] = (ypre+255)/radio  # 量化预测误差\n",
    "                img_re[j + i * w] = (yprebuff[j + i * w]-255/radio)*radio+128  # 重建像素,j解码\n",
    "                if img_re[j + i * w]>255:\n",
    "                    img_re[j + i * w] = 255# 防止重建像素超过255\n",
    "                yprebuff[j + i * w] = yprebuff[j + i * w]*radio/2\n",
    "\n",
    "            else:\n",
    "                ypre = y[j + i * w] - img_re[j + i * w - 1]  # 计算预测误差\n",
    "                yprebuff[j + i * w] = (ypre+255) /radio  # 量化  # 量化器\n",
    "                img_re[j + i * w] = (yprebuff[j + i * w]-255/radio)*radio+img_re[j + i * w - 1]  # 反量化\n",
    "                yprebuff[j + i * w] = yprebuff[j + i * w] * radio / 2  # 预测器\n",
    "                if img_re[j + i * w]>255:\n",
    "                    img_re[j + i * w] = 255# 防止重建电平超过255\n",
    "    img_re = img_re.astype(np.uint8) # 用来存储重建图像,后面转回uint8\n",
    "    yprebuff = yprebuff.astype(np.uint8)  # 预测误差\n",
    "\n",
    "    ##########################################################################################\n",
    "    # 重建图片\n",
    "    y = y.reshape((h,w))  # 转换向量形状回原来的y分量\n",
    "\n",
    "    yprebuff = yprebuff.reshape((h,w))  # 预测的y分量\n",
    "\n",
    "    img_re = img_re.reshape((h,w))  # 重建的y分量\n",
    "\n",
    "    u = u.reshape((h//2,w//2))  # 恢复采样后的u分量\n",
    "    v = v.reshape((h//2,w//2))\n",
    "    ru = cv2.resize(u,(w,h))  # 恢复采样前的u分量，用这个u分量来重建图片文件\n",
    "    rv = cv2.resize(v,(w,h))\n",
    "\n",
    "    yvu = cv2.merge((y, rv, ru))\n",
    "    bgr = cv2.cvtColor(yvu, cv2.COLOR_YCrCb2BGR)  # 将原来的y,u,v分量转换回图片\n",
    "\n",
    "    yvu_pre = cv2.merge((yprebuff, rv, ru))\n",
    "    bgr_pre = cv2.cvtColor(yvu_pre, cv2.COLOR_YCrCb2BGR)  # 将y的预测误差转换为图片\n",
    "\n",
    "    yvu_re = cv2.merge((img_re, rv, ru))\n",
    "    bgr_re = cv2.cvtColor(yvu_re, cv2.COLOR_YCrCb2BGR)  # 将解码后的的y,u,v分量转换回原图\n",
    "\n",
    "    ###############################################################################\n",
    "    print(\"PSNR:\",peak_signal_noise_ratio(bgr,bgr_re))\n",
    "    print(\"SSIM:\",structural_similarity(bgr,bgr_re))\n",
    "    # 显示结果\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "    plt.subplot(241), plt.imshow(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)),\n",
    "    plt.title('原图'), plt.axis('off')\n",
    "    plt.subplot(242), plt.imshow(cv2.cvtColor(bgr_pre, cv2.COLOR_BGR2RGB), cmap='gray'),\n",
    "    plt.title('预测误差'), plt.axis('off')\n",
    "    plt.subplot(243), plt.imshow(cv2.cvtColor(bgr_re, cv2.COLOR_BGR2RGB), cmap='gray'),\n",
    "    plt.title('重建'), plt.axis('off')\n",
    "\n",
    "main(8)\n",
    "main(4)\n",
    "main(2)\n",
    "main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "030c80840b0d9f5db79d93d54f37f04cee5e760b761780c141ee4f016f609d74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
