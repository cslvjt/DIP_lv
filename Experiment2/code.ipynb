{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "+ https://www.cnblogs.com/Imageshop/p/3281703.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "## 什么是暗通道？\n",
    "在绝大多数非天空的局部区域里，某些像素总会有某个颜色通道很低的值，用数学表达式定义的话就是$J^{dark}(x)=\\min_{y\\in \\Omega (x)}(\\min_{c\\in \\{r,g,b\\}}J^c(y))$\n",
    "，其中$J^c$表示彩色图像的每一个通道，$\\Omega (x)$表示以像素x为中心的一个窗口。实际计算过程中可以理解为，首先对图像求出每一个像素RGB三通道中的最小值，然后进行以此最小值滤波,即可求出$J^{dark}$\n",
    "## 暗通道有什么先验知识？\n",
    "$J^{dark}-->0$\n",
    "## 如何利用暗通道进行去雾？\n",
    "首先了解雾图像形成模型：$I(x)=J(x)t(x)+A(1-t(x))$，其中$I(x)$为雾图,$J(x)$为无雾图，A是全球大气光成分，$t(x)$为透射率。\n",
    "\n",
    "接下来就是推导过程：\n",
    "<img src=./img/darkChannel.jpeg>\n",
    "上述推论中都是假设全球达气光A值时已知的，在实际中，我们可以借助于暗通道图来从有雾图像中获取该值。具体步骤如下：\n",
    "\n",
    "1、从**暗通道**图中按照亮度的大小取前0.1%的像素。\n",
    "\n",
    "2、在这些位置中，在**原始有雾图像I**中寻找对应的具有最高亮度的点的值，作为A值。\n",
    "\n",
    "到这一步，我们就可以进行无雾图像的恢复了。由上式可知：J=(I-A)/t+A  \n",
    "现在I,A,t都已经求得了，因此，完全可以进行J的计算。\n",
    "\n",
    "当投射图t的值很小时，会导致J的值偏大，从而使淂图像整体向白场过度，因此一般可设置一阈值T0，当t值小于T0时，令t=T0，本文中所有效果图均以T0=0.1为标准计算。\n",
    "因此最终的恢复公式：\n",
    "$J(x)=\\frac{I(x)-A}{max(t(x),t_0)}+A$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from itertools import combinations_with_replacement\n",
    "from collections import defaultdict\n",
    "from numpy.linalg import inv\n",
    "\n",
    "'''\n",
    "J : haze free image\n",
    "I : hazy image\n",
    "t : 0 for haze free image and 1 for maximum hazy image\n",
    "'''\n",
    "\n",
    "class Dehazer:\n",
    "\tdef __init__(self,img,omega=0.95,t0=0.1,w=5,w_refine=40,epsilon=1e-2,refine=True,threshold_percentage=0.001,show_intermediate=False):\n",
    "\t\tself.image = img # Corresponds to I in the paper\n",
    "\t\tself.omega = omega\n",
    "\t\tself.t0 = t0\n",
    "\t\tself.w = w\n",
    "\t\tself.w_refine = w_refine\n",
    "\t\tself.epsilon = epsilon\n",
    "\t\tself.refine = refine\n",
    "\t\tself.show_intermediate = show_intermediate\n",
    "\t\tself.threshold_percentage = threshold_percentage\n",
    "\n",
    "\tdef get_dark_channel(self):\n",
    "\t\t'''\n",
    "\t\tw : window size\n",
    "\t\tAdd docstring\n",
    "\t\t'''\n",
    "\t\tw = self.w\n",
    "\t\tself.dark_channel = np.zeros((self.image.shape[0],self.image.shape[1],1))\n",
    "\t\tpadded_image = np.pad(self.image,((int(w/2),int(w/2)),(int(w/2),int(w/2)),(0,0)),'edge')\n",
    "\n",
    "\t\tfor i in range(int(w/2),padded_image.shape[0] - int(w/2)):\n",
    "\t\t\tfor j in range(int(w/2),padded_image.shape[1] - int(w/2)):\n",
    "\t\t\t\tblock = padded_image[i-int(w/2):i+int(w/2)+1,j-int(w/2):j+int(w/2)+1,:]\n",
    "\t\t\t\tself.dark_channel[i-int(w/2),j-int(w/2),0] = np.min(block)\n",
    "\n",
    "\t\t# if self.show_intermediate is True:\n",
    "\t\t# \tcv2.imshow('Dark Channel Image',self.dark_channel)\n",
    "\t\t# \tcv2.waitKey(0)\n",
    "\n",
    "\tdef get_A(self):\n",
    "\t\t'''\n",
    "\t\tAdd docstring\n",
    "\t\t'''\n",
    "\t\t# TODO : See the computationally efficient implementation\n",
    "\n",
    "\t\tself.get_dark_channel()\n",
    "\n",
    "\t\t# Calculate distribution \n",
    "\t\tfrequencies = np.zeros(256).astype(int)\n",
    "\t\tfor i in range(0,self.dark_channel.shape[0]):\n",
    "\t\t\tfor j in range(0,self.dark_channel.shape[1]):\n",
    "\t\t\t\tfrequencies[int(self.dark_channel[i,j,0])]+=1\n",
    "\n",
    "\t\tassert sum(frequencies) == self.image.shape[0]*self.image.shape[1]\n",
    "\t\t\n",
    "\t\t# print('Frequencies : {}'.format(frequencies))\n",
    "\n",
    "\t\t# Find the top 1% brightest pixels in the dark channel image\n",
    "\t\tthreshold = self.threshold_percentage*sum(frequencies)\n",
    "\t\t# print('Threshold : {}'.format(threshold))\n",
    "\n",
    "\t\trev_freq = np.flip(frequencies,axis=0)\n",
    "\t\tcum_sum = np.cumsum(rev_freq)\n",
    "\t\tindex = np.array(np.where(cum_sum <= threshold)).reshape(-1) # Stores the gray values which are in the top threshold percentage\n",
    "\n",
    "\t\ttop_gray_values = []\n",
    "\t\tsum_so_far = 0\n",
    "\n",
    "\t\tfor i in range(len(cum_sum)):\n",
    "\t\t\tif rev_freq[i] == 0:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tsum_so_far+=rev_freq[i]\n",
    "\t\t\ttop_gray_values.append(255 - i)\n",
    "\t\t\tif sum_so_far > threshold:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\t# # Seperate gray values not present in the dark channel image\n",
    "\t\t# for i in index:\n",
    "\t\t# \tif rev_freq[i] == 0:\n",
    "\t\t# \t\tcontinue\n",
    "\t\t# \ttop_gray_values.append(255 - i)\n",
    "\t\t\n",
    "\t\t# print('Top Gray Values : {}'.format(top_gray_values))\n",
    "\t\tA = np.zeros((1,3))\n",
    "\n",
    "\t\tmax_in_b = max_in_g = max_in_r = -1.0*float('inf')\n",
    "\n",
    "\t\t# Find maximum for each channel across these values\n",
    "\t\tfor tg in top_gray_values:\n",
    "\t\t\tindices = np.where(self.dark_channel == tg)\n",
    "\t\t\titerater_ = zip(indices[0],indices[1])\n",
    "\t\n",
    "\t\t\tfor i,j in iterater_:\n",
    "\t\t\t\tc = 0 # Channel under consideration\n",
    "\t\t\t\tif(self.image[i,j,c] > max_in_b):\n",
    "\t\t\t\t\tmax_in_b = self.image[i,j,c]\n",
    "\t\t\t\tc = 1\n",
    "\t\t\t\tif(self.image[i,j,c] > max_in_g):\n",
    "\t\t\t\t\tmax_in_g = self.image[i,j,c]\n",
    "\t\t\t\tc = 2\n",
    "\t\t\t\tif(self.image[i,j,c] > max_in_r):\n",
    "\t\t\t\t\tmax_in_r = self.image[i,j,c]\n",
    "\n",
    "\t\tA[0,0] = max_in_b\n",
    "\t\tA[0,1] = max_in_g\n",
    "\t\tA[0,2] = max_in_r\n",
    "\n",
    "\t\tself.A = A.reshape(1,1,3)\n",
    "\n",
    "\t\tif self.show_intermediate is True:\n",
    "\t\t\tprint(A)\n",
    "\n",
    "\tdef get_transmission_map(self):\n",
    "\t\tself.get_A()\n",
    "\t\tnormalized_haze_image = self.image/self.A\n",
    "\t\tw = self.w\n",
    "\n",
    "\t\tself.transmission_map = np.zeros((normalized_haze_image.shape[0],normalized_haze_image.shape[1],1))\n",
    "\t\tpadded_image = np.pad(normalized_haze_image,((int(w/2),int(w/2)),(int(w/2),int(w/2)),(0,0)),'edge')\n",
    "\n",
    "\t\tfor i in range(int(w/2),padded_image.shape[0] - int(w/2)):\n",
    "\t\t\tfor j in range(int(w/2),padded_image.shape[1] - int(w/2)):\n",
    "\t\t\t\tblock = padded_image[i-int(w/2):i+int(w/2)+1,j-int(w/2):j+int(w/2)+1,:]\n",
    "\t\t\t\tself.transmission_map[i-int(w/2),j-int(w/2),0] = 1.0 - self.omega*np.min(block)\n",
    "\n",
    "\t\tif self.show_intermediate is True:\n",
    "\t\t\tprint(self.transmission_map)\n",
    "\t\t\tcv2.imshow('Transmission Map',self.transmission_map)\n",
    "\t\t\tcv2.waitKey(0)\n",
    "\n",
    "\tdef mean_filter(self,I, w):\n",
    "\t\tkernel = np.ones((w,w),np.float32)/(1.0*w*w)\n",
    "\t\treturn cv2.filter2D(I,-1,kernel)\n",
    "\n",
    "\tdef guided_filter(self,I, p):\n",
    "\t    \"\"\"Refine a filter under the guidance of another (RGB) image.\n",
    "\t    Parameters\n",
    "\t    -----------\n",
    "\t    I:   an M * N * 3 RGB image for guidance.\n",
    "\t    p:   the M * N filter to be guided\n",
    "\t    r:   the radius of the guidance\n",
    "\t    eps: epsilon for the guided filter\n",
    "\t    Return\n",
    "\t    -----------\n",
    "\t    The guided filter.\n",
    "\t    \"\"\"\n",
    "\t    R,G,B = 0, 1, 2\n",
    "\t    w = self.w_refine\n",
    "\t    eps = self.epsilon\n",
    "\n",
    "\t    p = p.reshape(p.shape[0],p.shape[1])\n",
    "\t    M, N = self.image.shape[0],self.image.shape[1]\n",
    "\t    # base = self.mean_filter(np.ones((M, N)), w)\n",
    "\n",
    "\t    # print('Base : {}'.format(base))\n",
    "\t    # means = [self.mean_filter(I[:, :, i], w) / base for i in range(3)]\n",
    "\t    # print(means)\n",
    "\n",
    "\t    # each channel of I filtered with the mean filter\n",
    "\t    means = [self.mean_filter(I[:, :, i], w) for i in range(3)] # mu_k\n",
    "\t    # print(means)\n",
    "\n",
    "\t    # p filtered with the mean filter\n",
    "\t    mean_p = self.mean_filter(p, w) # p_k_bar\n",
    "\t    # filter I with p then filter it with the mean filter\n",
    "\t    means_IP = [self.mean_filter(I[:, :, i] * p, w) for i in range(3)] # First term in second bracket of equation 14\n",
    "\t    # covariance of (I, p) in each local patch\n",
    "\t    covIP = [means_IP[i] - means[i] * mean_p for i in range(3)] # Second term in equation 14\n",
    "\n",
    "\t    '''\n",
    "\t    Equation 14 describes an image as the second term...the summation is nothing but a mean filter applied to every pixel\n",
    "\t    '''\n",
    "\n",
    "\t    # variance of I in each local patch: the matrix Sigma in eq.14\n",
    "\t    var = defaultdict(dict)\n",
    "\t    for i, j in combinations_with_replacement(range(3), 2):\n",
    "\t        var[i][j] = self.mean_filter(\n",
    "\t            I[:, :, i] * I[:, :, j], w) - means[i] * means[j] # Matrix Sigma terms for each pixel\n",
    "\n",
    "\t    a = np.zeros((M, N, 3))\n",
    "\t    for y, x in np.ndindex(M, N):\n",
    "\t        #         rr, rg, rb\n",
    "\t        # Sigma = rg, gg, gb\n",
    "\t        #         rb, gb, bb\n",
    "\t        Sigma = np.array([[var[R][R][y, x], var[R][G][y, x], var[R][B][y, x]],\n",
    "\t                          [var[R][G][y, x], var[G][G][y, x], var[G][B][y, x]],\n",
    "\t                          [var[R][B][y, x], var[G][B][y, x], var[B][B][y, x]]])\n",
    "\t        cov = np.array([c[y, x] for c in covIP])\n",
    "\t        a[y, x] = np.dot(cov, inv(Sigma + eps * np.eye(3)))  # eq 14\n",
    "\t    \n",
    "\t    b = mean_p - a[:, :, R] * means[R] - a[:, :, G] * means[G] - a[:, :, B] * means[B] # Equation 15\n",
    "\n",
    "\t    q = (self.mean_filter(a[:, :, R], w) * I[:, :, R] + self.mean_filter(a[:, :, G], w) *\n",
    "\t         I[:, :, G] + self.mean_filter(a[:, :, B], w) * I[:, :, B] + self.mean_filter(b, w)) # Equations 7,8,16\n",
    "\n",
    "\t    self.refined_transmission_map = q.reshape(q.shape[0],q.shape[1],1)\n",
    "\n",
    "\tdef refine_transmission_map(self):\n",
    "\t\tnormalized_image = (self.image - self.image.min())/(self.image.max() - self.image.min())\n",
    "\t\tself.guided_filter(normalized_image,self.transmission_map)\n",
    "\n",
    "\t\tif self.show_intermediate is True:\n",
    "\t\t\tprint(self.refined_transmission_map)\n",
    "\t\t\tcv2.imshow('Refined Transmission Map',self.refined_transmission_map)\n",
    "\t\t\tcv2.waitKey(0)\n",
    "\n",
    "\tdef dehaze(self):\n",
    "\t\tself.get_transmission_map()\n",
    "\n",
    "\t\tif self.refine is True:\n",
    "\t\t\tself.refine_transmission_map()\n",
    "\n",
    "\t\t# Normalizing I and A\n",
    "\t\tself.image = (self.image - np.min(self.image))/(np.max(self.image) - np.min(self.image))\n",
    "\t\tself.A/=255.0\n",
    "\n",
    "\t\tif self.refine is True:\n",
    "\t\t\tself.J = (self.image - self.A)/(np.maximum(self.refined_transmission_map,self.t0)) + self.A\n",
    "\t\telse:\n",
    "\t\t\tself.J = (self.image - self.A)/(np.maximum(self.transmission_map,self.t0)) + self.A\n",
    "\n",
    "\t\tif self.show_intermediate is True:\n",
    "\t\t\tprint(self.J)\n",
    "\t\t\tcv2.imshow('Dehazed Image',self.J)\n",
    "\t\t\tcv2.waitKey(0)\n",
    "\n",
    "\t\treturn self.J*255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2;\n",
    "import math;\n",
    "import numpy as np;\n",
    "\n",
    "# 求出暗通道\n",
    "def DarkChannel(im,sz):\n",
    "    \"\"\"\n",
    "    im:输入图像\n",
    "    sz:窗口大小\n",
    "    \"\"\"\n",
    "    b,g,r = cv2.split(im)\n",
    "    dc = cv2.min(cv2.min(r,g),b);\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
    "    dark = cv2.erode(dc,kernel)\n",
    "    return dark\n",
    "\n",
    "# 求出全球大气光值A\n",
    "def AtmLight(im,dark):\n",
    "    [h,w] = im.shape[:2]\n",
    "    imsz = h*w\n",
    "    numpx = int(max(math.floor(imsz/1000),1))\n",
    "    darkvec = dark.reshape(imsz);\n",
    "    imvec = im.reshape(imsz,3);\n",
    "\n",
    "    indices = darkvec.argsort();\n",
    "    indices = indices[imsz-numpx::]\n",
    "\n",
    "    atmsum = np.zeros([1,3])\n",
    "    for ind in range(1,numpx):\n",
    "       atmsum = atmsum + imvec[indices[ind]]\n",
    "\n",
    "    A = atmsum / numpx;\n",
    "    return A\n",
    "\n",
    "def TransmissionEstimate(im,A,sz):\n",
    "    omega = 0.95;\n",
    "    im3 = np.empty(im.shape,im.dtype);\n",
    "\n",
    "    for ind in range(0,3):\n",
    "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
    "\n",
    "    transmission = 1 - omega*DarkChannel(im3,sz);\n",
    "    return transmission\n",
    "\n",
    "def Guidedfilter(im,p,r,eps):\n",
    "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n",
    "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n",
    "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n",
    "    cov_Ip = mean_Ip - mean_I*mean_p;\n",
    "\n",
    "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n",
    "    var_I   = mean_II - mean_I*mean_I;\n",
    "\n",
    "    a = cov_Ip/(var_I + eps);\n",
    "    b = mean_p - a*mean_I;\n",
    "\n",
    "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n",
    "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n",
    "\n",
    "    q = mean_a*im + mean_b;\n",
    "    return q;\n",
    "\n",
    "def TransmissionRefine(im,et):\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n",
    "    gray = np.float64(gray)/255;\n",
    "    r = 60;\n",
    "    eps = 0.0001;\n",
    "    t = Guidedfilter(gray,et,r,eps);\n",
    "\n",
    "    return t;\n",
    "\n",
    "def Recover(im,t,A,tx = 0.1):\n",
    "    res = np.empty(im.shape,im.dtype);\n",
    "    t = cv2.max(t,tx);\n",
    "\n",
    "    for ind in range(0,3):\n",
    "        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n",
    "\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fn = 'T:\\GitHub\\DIP_lv\\Experiment2\\img\\haze.png'\n",
    "\n",
    "\n",
    "    src = cv2.imread(fn);\n",
    "\n",
    "    I = src.astype('float64')/255;\n",
    " \n",
    "    dark = DarkChannel(I,15);\n",
    "    A = AtmLight(I,dark);\n",
    "    te = TransmissionEstimate(I,A,15);\n",
    "    t = TransmissionRefine(src,te);\n",
    "    J = Recover(I,t,A,0.1);\n",
    "\n",
    "    cv2.imshow(\"dark\",dark);\n",
    "    cv2.imshow(\"t\",t);\n",
    "    cv2.imshow('I',src);\n",
    "    cv2.imshow('J',J);\n",
    "    cv2.imwrite(\"./image/J.png\",J*255);\n",
    "    cv2.waitKey();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#获取暗通道\n",
    "def getDarkChannel(img,windowSize):\n",
    "    \"\"\"\n",
    "    img:输入图像\n",
    "    windowSize:窗口大小\n",
    "    \"\"\"\n",
    "    b,g,r=cv2.split(img)\n",
    "    darkC=cv2.min(cv2.min(r,g),b)\n",
    "    \"\"\"\n",
    "    #cv2.getStructuringElement( ) 返回指定形状和尺寸的结构元素\n",
    "    矩形:MORPH_RECT;\n",
    "    交叉形:MORPH_CROSS;\n",
    "    椭圆形:MORPH_ELLIPSE;\n",
    "    第二和第三个参数分别是内核的尺寸以及锚点的位置\n",
    "    \"\"\"\n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(windowSize,windowSize))\n",
    "    \"\"\"\n",
    "    二值图像f(x,y) 的膨胀操作，类似于对图像的卷积操作.\n",
    "    需要有个 kernel 操作矩阵，类似于卷积核(filters, kernel)，常见的是 3X3 的矩阵. 这是形态学处理的核心.\n",
    "    但与卷积不同的是，如果矩阵中的像素点有任意一个点的值是前景色，则设置中心像素点为前景色；否则不变.\n",
    "    最小值卷积相当于腐蚀操作\n",
    "    \"\"\"\n",
    "    darkChannel=cv2.erode(darkC,kernel)\n",
    "    return darkChannel\n",
    "\n",
    "# 求出全球大气光值\n",
    "def AtmLight(img,darkChannel):\n",
    "    \"\"\"\n",
    "    img:图像\n",
    "    darkChannel: 暗通道\n",
    "    \"\"\"\n",
    "    [h,w]=img.shape[:2]\n",
    "    imgSize=h*w\n",
    "    numpx = int(max(math.floor(imgSize/1000),1))\n",
    "    darkvec = dark.reshape(imgSize)\n",
    "    imvec = img.reshape(imgSize,3)\n",
    "\n",
    "    indices = darkvec.argsort()\n",
    "    indices = indices[imgSize-numpx::]\n",
    "\n",
    "    atmsum = np.zeros([1,3])\n",
    "    for channel_index in range(1,numpx):\n",
    "       atmsum = atmsum + imvec[indices[channel_index]]\n",
    "\n",
    "    A = atmsum / numpx\n",
    "    return A\n",
    "\n",
    "def TransmissionEstimate(im,A,sz):\n",
    "    omega = 0.95\n",
    "    im3 = np.empty(im.shape,im.dtype)\n",
    "    for ind in range(0,3):\n",
    "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
    "\n",
    "    transmission = 1 - omega*getDarkChannel(im3,sz)\n",
    "    return transmission\n",
    "\n",
    "def Guidedfilter(im,p,r,eps):\n",
    "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r))\n",
    "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r))\n",
    "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r))\n",
    "    cov_Ip = mean_Ip - mean_I*mean_p\n",
    "\n",
    "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r))\n",
    "    var_I   = mean_II - mean_I*mean_I\n",
    "\n",
    "    a = cov_Ip/(var_I + eps)\n",
    "    b = mean_p - a*mean_I\n",
    "\n",
    "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r))\n",
    "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r))\n",
    "\n",
    "    q = mean_a*im + mean_b\n",
    "    return q;\n",
    "\n",
    "def TransmissionRefine(im,et):\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float64(gray)/255\n",
    "    r = 60\n",
    "    eps = 0.0001\n",
    "    t = Guidedfilter(gray,et,r,eps)\n",
    "\n",
    "    return t\n",
    "\n",
    "def recover(img,t,A,tx=0.1):\n",
    "    \"\"\"\n",
    "    img:雾图像\n",
    "    t: 投射图\n",
    "    A: 大气光值\n",
    "    tx: 投射图阈值\n",
    "    \"\"\"\n",
    "    result=np.empty(img.shape,img.dtype)\n",
    "    t=cv2.max(t,tx)\n",
    "\n",
    "    for channel_index in range(0,3):\n",
    "        result[:,:,channel_index]=(img[:,:,channel_index]-A[0,channel_index])/t+A[0:channel_index]\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fn = 'T:\\GitHub\\DIP_lv\\Experiment2\\img\\haze.png'\n",
    "\n",
    "\n",
    "    src = cv2.imread(fn);\n",
    "\n",
    "    I = src.astype('float64')/255;\n",
    " \n",
    "    dark = getDarkChannel(I,15);\n",
    "    A = AtmLight(I,dark);\n",
    "    te = TransmissionEstimate(I,A,15);\n",
    "    t = TransmissionRefine(src,te);\n",
    "    J = recover(I,t,A,0.1);\n",
    "\n",
    "    cv2.imshow(\"dark\",dark);\n",
    "    cv2.imshow(\"t\",t);\n",
    "    cv2.imshow('I',src);\n",
    "    cv2.imshow('J',J);\n",
    "    cv2.imwrite(\"T:\\GitHub\\DIP_lv\\Experiment2\\img\\J.png\",J*255);\n",
    "    cv2.waitKey();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "030c80840b0d9f5db79d93d54f37f04cee5e760b761780c141ee4f016f609d74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
