{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "+ https://www.cnblogs.com/Imageshop/p/3281703.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "## 什么是暗通道？\n",
    "在绝大多数非天空的局部区域里，某些像素总会有某个颜色通道很低的值，用数学表达式定义的话就是$J^{dark}(x)=\\min_{y\\in \\Omega (x)}(\\min_{c\\in \\{r,g,b\\}}J^c(y))$\n",
    "，其中$J^c$表示彩色图像的每一个通道，$\\Omega (x)$表示以像素x为中心的一个窗口。实际计算过程中可以理解为，首先对图像求出每一个像素RGB三通道中的最小值，然后进行以此最小值滤波,即可求出$J^{dark}$\n",
    "## 暗通道有什么先验知识？\n",
    "$J^{dark}-->0$\n",
    "## 如何利用暗通道进行去雾？\n",
    "首先了解雾图像形成模型：$I(x)=J(x)t(x)+A(1-t(x))$，其中$I(x)$为雾图,$J(x)$为无雾图，A是全球大气光成分，$t(x)$为透射率。\n",
    "\n",
    "接下来就是推导过程：\n",
    "<img src=./img/darkChannel.jpeg>\n",
    "上述推论中都是假设全球达气光A值时已知的，在实际中，我们可以借助于暗通道图来从有雾图像中获取该值。具体步骤如下：\n",
    "\n",
    "1、从**暗通道**图中按照亮度的大小取前0.1%的像素。\n",
    "\n",
    "2、在这些位置中，在**原始有雾图像I**中寻找对应的具有最高亮度的点的值，作为A值。\n",
    "\n",
    "到这一步，我们就可以进行无雾图像的恢复了。由上式可知：J=(I-A)/t+A  \n",
    "现在I,A,t都已经求得了，因此，完全可以进行J的计算。\n",
    "\n",
    "当投射图t的值很小时，会导致J的值偏大，从而使淂图像整体向白场过度，因此一般可设置一阈值T0，当t值小于T0时，令t=T0，本文中所有效果图均以T0=0.1为标准计算。\n",
    "因此最终的恢复公式：\n",
    "$J(x)=\\frac{I(x)-A}{max(t(x),t_0)}+A$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2;\n",
    "import math;\n",
    "import numpy as np;\n",
    "\n",
    "# 求出暗通道\n",
    "def DarkChannel(im,sz):\n",
    "    \"\"\"\n",
    "    im:输入图像\n",
    "    sz:窗口大小\n",
    "    \"\"\"\n",
    "    b,g,r = cv2.split(im)\n",
    "    dc = cv2.min(cv2.min(r,g),b);\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
    "    dark = cv2.erode(dc,kernel)\n",
    "    return dark\n",
    "\n",
    "# 求出全球大气光值A\n",
    "def AtmLight(im,dark):\n",
    "    [h,w] = im.shape[:2]\n",
    "    imsz = h*w\n",
    "    numpx = int(max(math.floor(imsz/1000),1))\n",
    "    darkvec = dark.reshape(imsz);\n",
    "    imvec = im.reshape(imsz,3);\n",
    "\n",
    "    indices = darkvec.argsort();\n",
    "    indices = indices[imsz-numpx::]\n",
    "\n",
    "    atmsum = np.zeros([1,3])\n",
    "    for ind in range(1,numpx):\n",
    "       atmsum = atmsum + imvec[indices[ind]]\n",
    "\n",
    "    A = atmsum / numpx;\n",
    "    return A\n",
    "\n",
    "def TransmissionEstimate(im,A,sz):\n",
    "    omega = 0.95;\n",
    "    im3 = np.empty(im.shape,im.dtype);\n",
    "\n",
    "    for ind in range(0,3):\n",
    "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
    "\n",
    "    transmission = 1 - omega*DarkChannel(im3,sz);\n",
    "    return transmission\n",
    "\n",
    "def Guidedfilter(im,p,r,eps):\n",
    "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n",
    "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n",
    "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n",
    "    cov_Ip = mean_Ip - mean_I*mean_p;\n",
    "\n",
    "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n",
    "    var_I   = mean_II - mean_I*mean_I;\n",
    "\n",
    "    a = cov_Ip/(var_I + eps);\n",
    "    b = mean_p - a*mean_I;\n",
    "\n",
    "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n",
    "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n",
    "\n",
    "    q = mean_a*im + mean_b;\n",
    "    return q;\n",
    "\n",
    "def TransmissionRefine(im,et):\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n",
    "    gray = np.float64(gray)/255;\n",
    "    r = 60;\n",
    "    eps = 0.0001;\n",
    "    t = Guidedfilter(gray,et,r,eps);\n",
    "\n",
    "    return t;\n",
    "\n",
    "def Recover(im,t,A,tx = 0.1):\n",
    "    res = np.empty(im.shape,im.dtype);\n",
    "    t = cv2.max(t,tx);\n",
    "\n",
    "    for ind in range(0,3):\n",
    "        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n",
    "\n",
    "    return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fn = 'T:\\GitHub\\DIP_lv\\Experiment2\\img\\haze.png'\n",
    "\n",
    "\n",
    "    src = cv2.imread(fn);\n",
    "\n",
    "    I = src.astype('float64')/255;\n",
    " \n",
    "    dark = DarkChannel(I,15);\n",
    "    A = AtmLight(I,dark);\n",
    "    te = TransmissionEstimate(I,A,15);\n",
    "    t = TransmissionRefine(src,te);\n",
    "    J = Recover(I,t,A,0.1);\n",
    "\n",
    "    cv2.imshow(\"dark\",dark);\n",
    "    cv2.imshow(\"t\",t);\n",
    "    cv2.imshow('I',src);\n",
    "    cv2.imshow('J',J);\n",
    "    cv2.imwrite(\"./image/J.png\",J*255);\n",
    "    cv2.waitKey();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "#获取暗通道\n",
    "def getDarkChannel(img,windowSize):\n",
    "    \"\"\"\n",
    "    img:输入图像\n",
    "    windowSize:窗口大小\n",
    "    \"\"\"\n",
    "    b,g,r=cv2.split(img)\n",
    "    darkC=cv2.min(cv2.min(r,g),b)\n",
    "    \"\"\"\n",
    "    #cv2.getStructuringElement( ) 返回指定形状和尺寸的结构元素\n",
    "    矩形:MORPH_RECT;\n",
    "    交叉形:MORPH_CROSS;\n",
    "    椭圆形:MORPH_ELLIPSE;\n",
    "    第二和第三个参数分别是内核的尺寸以及锚点的位置\n",
    "    \"\"\"\n",
    "    kernel=cv2.getStructuringElement(cv2.MORPH_RECT,(windowSize,windowSize))\n",
    "    \"\"\"\n",
    "    二值图像f(x,y) 的膨胀操作，类似于对图像的卷积操作.\n",
    "    需要有个 kernel 操作矩阵，类似于卷积核(filters, kernel)，常见的是 3X3 的矩阵. 这是形态学处理的核心.\n",
    "    但与卷积不同的是，如果矩阵中的像素点有任意一个点的值是前景色，则设置中心像素点为前景色；否则不变.\n",
    "    最小值卷积相当于腐蚀操作\n",
    "    \"\"\"\n",
    "    darkChannel=cv2.erode(darkC,kernel)\n",
    "    return darkChannel\n",
    "\n",
    "# 求出全球大气光值\n",
    "def AtmLight(img,darkChannel):\n",
    "    \"\"\"\n",
    "    img:图像\n",
    "    darkChannel: 暗通道\n",
    "    \"\"\"\n",
    "    [h,w]=img.shape[:2]\n",
    "    imgSize=h*w\n",
    "    numpx = int(max(math.floor(imgSize/1000),1))\n",
    "    darkvec = dark.reshape(imgSize)\n",
    "    imvec = img.reshape(imgSize,3)\n",
    "\n",
    "    indices = darkvec.argsort()\n",
    "    indices = indices[imgSize-numpx::]\n",
    "\n",
    "    atmsum = np.zeros([1,3])\n",
    "    for channel_index in range(1,numpx):\n",
    "       atmsum = atmsum + imvec[indices[channel_index]]\n",
    "\n",
    "    A = atmsum / numpx\n",
    "    return A\n",
    "# 估计t值\n",
    "def TransmissionEstimate(im,A,sz):\n",
    "    omega = 0.95\n",
    "    im3 = np.empty(im.shape,im.dtype)\n",
    "    for ind in range(0,3):\n",
    "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
    "\n",
    "    transmission = 1 - omega*getDarkChannel(im3,sz)\n",
    "    return transmission\n",
    "\n",
    "# 导向滤波\n",
    "def Guidedfilter(im,p,r,eps):\n",
    "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r))\n",
    "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r))\n",
    "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r))\n",
    "    cov_Ip = mean_Ip - mean_I*mean_p\n",
    "\n",
    "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r))\n",
    "    var_I   = mean_II - mean_I*mean_I\n",
    "\n",
    "    a = cov_Ip/(var_I + eps)\n",
    "    b = mean_p - a*mean_I\n",
    "\n",
    "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r))\n",
    "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r))\n",
    "\n",
    "    q = mean_a*im + mean_b\n",
    "    return q;\n",
    "# 进一步修正t值。soft matting方法，能够得到非常细腻的结果。采用导向滤波的方法。\n",
    "def TransmissionRefine(im,et):\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float64(gray)/255\n",
    "    r = 60\n",
    "    eps = 0.0001\n",
    "    t = Guidedfilter(gray,et,r,eps)\n",
    "\n",
    "    return t\n",
    "\n",
    "def recover(img,t,A,tx=0.1):\n",
    "    \"\"\"\n",
    "    img:雾图像\n",
    "    t: 投射图\n",
    "    A: 大气光值\n",
    "    tx: 投射图阈值\n",
    "    \"\"\"\n",
    "    result=np.empty(img.shape,img.dtype)\n",
    "    t=cv2.max(t,tx)\n",
    "\n",
    "    for channel_index in range(0,3):\n",
    "        result[:,:,channel_index]=(img[:,:,channel_index]-A[0,channel_index])/t+A[0,channel_index]\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fn = r'.\\img\\haze.png'\n",
    "\n",
    "\n",
    "    src = cv2.imread(fn);\n",
    "\n",
    "    I = src.astype('float64')/255\n",
    " \n",
    "    dark = getDarkChannel(I,15)\n",
    "    A = AtmLight(I,dark)\n",
    "    te = TransmissionEstimate(I,A,15)\n",
    "    t = TransmissionRefine(src,te)\n",
    "    clear_output = recover(I,t,A,0.1)\n",
    "\n",
    "    cv2.imshow(\"dark\",dark)\n",
    "    cv2.imshow(\"t\",t)\n",
    "    cv2.imshow('I',src)\n",
    "    cv2.imshow('J',clear_output)\n",
    "    cv2.imwrite(r\".\\img\\J_te.png\",clear_output*255)\n",
    "    cv2.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "030c80840b0d9f5db79d93d54f37f04cee5e760b761780c141ee4f016f609d74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
